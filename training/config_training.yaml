##############################################################
################## MODEL BUILDING SETTINGS ###################
##############################################################

######################
# METRICS MONITORING #
######################

# For monitoring metrics
mlflow:
  experiment_name: *current_exp
  tracking_uri: mlflow.get_tracking_uri()

# Experiment number for MLflow / Note that it is not possible
# to have the same experiment name multiple times
current_experiment: &current_exp experiment_4

########################
# Audio files settings #
########################
LENGTH_SEGMENTS: 3 # in seconds
SAMPLE_RATE: 44100

#################
# PATH SETTINGS #
#################

# Path to the audio dataset used for training and validation
PATH_TRAIN_VAL_DATASET: "/data/**" # For local usage: "/Data/audioCLIP/tiny_training/**" 

# Path for storing Pytorch lightning logs
path_lightning_metrics: "/app/"

# Path to the audio component of the test dataset 
TEST_PATH: '/Data/test_dataset/audio'

# Path to the labels of the test dataset
TEST_DF_PATH: '/Data/test_dataset/labels'

#####################
# TRAINING SETTINGS #
#####################

# fraction of the data to use for validation
PROP_TRAINING: 0.8 

# batch size used // DECREASE IF SHARED MEMORY PROBLEM
batch_size: 32

# number of epochs to run, due to stopping rule this number just needs to be big
n_epoch: 500

# number of epochs since last improvement before stopping training
STOPPING_RULE_PATIENCE: 10

# number of workers to use for data generation, change to 1 for debugging 
num_workers: 4

# On what hardware to train the model. Options include: cpu, gpu or tpu
accelerator: "gpu" 

# Pin memory for the dataloader
pin_memory: False

# Learning rate to use. NOTE that if using ray.tune you can change to tune.loguniform
learning_rate: "tune.loguniform(0.0001, 0.1)"

# Number of output neurons for the model
num_target_classes: 2

#####################
# RAY TUNE SETTINGS #
#####################

# Name of the ray experiment
name_experiment: "ray_experiment_0"

# Number of CPU available for each trial
n_cpu_per_trials: 4

# Number of GPU for each trial / NOTE THAT IN ITS CURRENT SETTINGS
# RAY TUNE USES ONE GPU FOR THE HEAD NODE, HAVE A LEAST 2 GPUS!!!
n_gpu_per_trials: 2

# Number of trials to do
n_sampling: 20

#######################
# TRANSFORMS SETTINGS #
#######################

# Regarding the choice of the augmentation see the post on StackExchange:
# https://bioacoustics.stackexchange.com/questions/98/data-augmentation-strategies-for-bioacoustics-machine-learning

# Parameters for the addition of Gaussian noise
GAUSSIAN_MIN_AMPLITUDE: 0.001
GAUSSIAN_MAX_AMPLITUDE: 0.015
GAUSSIAN_P: 0.5

# Parameters for SevenBandParametricEQ: 
# modifications to the frequency equalisation (this is similar to slightly 
# changing the response characteristics of your mic)
P_SEVENBANDPARAMETRICEQ: 0.5

# Time shifting
P_SHIFT: 0.5

# Parameters for AirAbsorption:
# emulating the effects of distance by adding a bit of low-pass filtering, 
# and/or some echo/reverb using an impulse response.
P_AIR_ABSORPTION: 0.5

# Time masking and frequency masking -- these don't have a very obvious interpretation but 
# are a kind of "dropout" of frequencies or time regions, and seem to help.
P_TIME_MASK: 0.5
P_FREQ_MASK: 0.5

#################
# TEST SETTINGS #
#################

# As of now there are only
# path settings. See section on PATH SETTINGS


# ? 

# Parameters for the performance run
num_samples: 1
